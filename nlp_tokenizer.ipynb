{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1-0C_Lr2DcuMMQaRPBZyz_8ofHFfbUeQH",
      "authorship_tag": "ABX9TyPhPzcKfLGf6pa4LmVridjL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laxmi-priya/Natural_language_processing/blob/main/nlp_tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYRK1KTL2V7J"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Dr. strange loves pav bhaji of mumbai. Hulk loves chaat of delhi\")\n",
        "\n",
        "for sentence in doc.sents:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "id": "3kv9_D242aGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in doc.sents:\n",
        "  for word in sentence:\n",
        "    print(word)"
      ],
      "metadata": {
        "id": "xIZkl4CY2soR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "F7dca9DY29iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "9ua0cJ363MIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(\"Dr. strange loves pav bhaji of mumbai. Hulk loves chaat of delhi\")"
      ],
      "metadata": {
        "id": "vhllp25c4BJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp('''\"Let's go to N.Y!\"''')\n",
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "id": "80ksaiyMsyfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(nlp)"
      ],
      "metadata": {
        "id": "jKaFDZJutarr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")"
      ],
      "metadata": {
        "id": "cM7qPCCp7KWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Dr. strange loves pav bhaji of mumbai as it cost only 2$ per plate\")\n",
        "for token in doc:\n",
        "  print(token)\n"
      ],
      "metadata": {
        "id": "Ap9XcZuc7bFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(nlp)"
      ],
      "metadata": {
        "id": "njELqXeH8Gg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(doc)"
      ],
      "metadata": {
        "id": "bhB99uC9thfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(token)"
      ],
      "metadata": {
        "id": "5ey2go40tk4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tony gave two $ to peter.\")"
      ],
      "metadata": {
        "id": "kvIVjtzMtovs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token0 = doc[0]\n",
        "token0"
      ],
      "metadata": {
        "id": "c7jc8ESst7u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(token0)"
      ],
      "metadata": {
        "id": "dmuJpfCGuBbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(token0)"
      ],
      "metadata": {
        "id": "1aIkxnJJuE1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token0.is_currency"
      ],
      "metadata": {
        "id": "6rWW8pZcuI2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc[2].text\n"
      ],
      "metadata": {
        "id": "wYAMe-tbuUrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token, \"==>\", \"index: \", token.i, \"is_alpha:\", token.is_alpha, \n",
        "          \"is_punct:\", token.is_punct, \n",
        "          \"like_num:\", token.like_num,\n",
        "          \"is_currency:\", token.is_currency,\n",
        "         )"
      ],
      "metadata": {
        "id": "YJ9T1ukGu1I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/nlp/students.txt\") as f:\n",
        "  text = f.readlines()\n",
        "text"
      ],
      "metadata": {
        "id": "beLXn4b70mww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" \".join(text)\n",
        "text"
      ],
      "metadata": {
        "id": "rGpq-Hle1J8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "emails = []\n",
        "for tokens in doc:\n",
        "  if tokens.like_email:\n",
        "    emails.append(tokens.text)\n",
        "emails\n",
        "\n",
        "   \n"
      ],
      "metadata": {
        "id": "Uupi7to11YSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"hi\")\n",
        "doc = nlp(\"भैया जी! 5000 ₹ उधार थे वो वापस देदो\")\n",
        "for tokens in doc:\n",
        "  print(tokens,tokens.is_currency,tokens.is_alpha,tokens.like_num)"
      ],
      "metadata": {
        "id": "z2ltuhlQ2VmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customizing Tokenizer"
      ],
      "metadata": {
        "id": "HJ3Xm-9O5zkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.symbols import ORTH\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
        "tokens = [token.text for token in doc]\n",
        "tokens"
      ],
      "metadata": {
        "id": "3EdZV8kF6CZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.tokenizer.add_special_case(\"gimme\", [\n",
        "    {ORTH: \"gim\"},\n",
        "    {ORTH: \"me\"},\n",
        "])\n",
        "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
        "tokens = [token.text for token in doc]\n",
        "tokens"
      ],
      "metadata": {
        "id": "Q2FrcPwP6StK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
        "for sentence in doc.sents:\n",
        "    print(sentence)"
      ],
      "metadata": {
        "id": "aYnu8Pzn6ZGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.add_pipe('sentencizer')"
      ],
      "metadata": {
        "id": "Cokr3pqu6bnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise"
      ],
      "metadata": {
        "id": "Cq_ZzRWV7WXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text='''\n",
        "Look for data to help you address the question. Governments are good\n",
        "sources because data from public research is often freely available. Good\n",
        "places to start include http://www.data.gov/, and http://www.science.\n",
        "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
        "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
        "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
        "'''"
      ],
      "metadata": {
        "id": "1c6cjxDD6gi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "url=[]\n",
        "for tokens in doc:\n",
        " if tokens.like_url:\n",
        "    url.append(tokens.text)\n",
        "url\n",
        "\n"
      ],
      "metadata": {
        "id": "j7Ap9pN77eQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "data_websites = [token.text for token in doc if token.like_url ] \n",
        "data_websites"
      ],
      "metadata": {
        "id": "heBUlvab9knF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
        "doc = nlp(transactions)\n",
        "for token in doc:\n",
        "  if token.like_num and doc[token.i+1].is_currency:\n",
        "    print(token.text,doc[token.i+1].text)\n"
      ],
      "metadata": {
        "id": "uQto8KTt9lGR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}